{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.3: Ribo-seq quality control and downstream analysis of the Rp-Bp results\n",
    "\n",
    "Through these sections, you wil learn how to use `matplotlib` to visualise the results.\n",
    "\n",
    "## Sections:\n",
    "   - 1.3.1 Ribo-seq quality control how-to.\n",
    "   - 1.3.2 Preprocessing analysis: standard rpbp preprocessing and more.\n",
    "   - 1.3.3 Prediction analysis: understand the output of rpbp.\n",
    "\n",
    "## Questions & Objectives:\n",
    "   - Learn how to identify \"good quality\" Ribo-seq data.\n",
    "   - Learn how to visualise the results.\n",
    "   - Understand and use the output of rpbp (ORF predictions).\n",
    "\n",
    "### After I will be able to:\n",
    "   - run the rpbp downstream analysis pipeline and assess the quality of the data;\n",
    "   - use the ORF predictions for follow-up studies.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1 Ribo-seq quality control how-to\n",
    "\n",
    "Depending on the efficiency of the rRNA removal step of the experimental protocol, small structured RNAs (rRNAs, tRNAs, or snoRNAs) may have to be removed in a first pre-processing step. The remaining reads are mapped using s splice-aware aligner (`STAR`), but reads can still map to multiple locations. Different strategies can be implemented to either rescue the reads, keep one primary alignment per read, or discard all multi-mapping reads altogether. Finally, only periodic reads are kept for the analysis. We will use the data from the output of `Flexbar` (reads filtered for quality, trimmed from adapters), `Bowtie2` (reads mapping to rRNA, clean reads), `STAR` (unique reads) and `rpbp` (periodic reads) to quantify the amount of reads filtered out at each step of the pipeline.\n",
    "\n",
    "In a high-quality Ribo-seq library, reads mostly map to coding sequences (CDS or Canonical) (typically >85%) and to the 5'UTR (up to 10%). A smaller proportion map to the 3'UTR. The amount of reads mapping to non-coding regions can vary, but in general the signal is not very strong. Using the results of the pipeline, we will explore how many ORFs are predicted in each regions. It is also possible to use other tools such as `bedtools coverage`, that uses the mapped data (before translation prediction).\n",
    "\n",
    "A characteristic feature of a high-quality Ribo-seq library is its read-length distribution, which typically peaks around 29 nt in eukaryotic organisms, however broader distributions can be observed under different protocols, depending on the nuclease treatment, the drugs/inhibitors used, *etc.* It is also known that different ribosomal conformation correspond to distinct read-length distributions, and that these can also be affected by ribosomes belonging to different pools (mitochondrial ribosomes were shown previously to display a bimodal distribution, compared to cytosolic-derived fragments). All these considerations must be taken into account when analysing the distribution of read lengths.\n",
    "\n",
    "We will briefly explore these and other aspects graphically, using the data from the example. We will be using the full data from 4 biological replicates. This data has been prepared before the course. \n",
    "\n",
    "&#9655;  **Self-guided learning** As a self-guided learning exercise, you can try to use this notebook and perform the analysis of the downsampled data that we ran in the previous notebook. Note that you will first need to run the standard `rpbp` preprocessing analysis (see further below). With the output of this analysis, you will be able to run the first 6 code cells below (*read filtering count*).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.2 Preprocessing analysis: standard rpbp preprocessing and more\n",
    "\n",
    "\n",
    "***\n",
    "<font color=red>**Note** The cells below contain \"code\", so we will need to run them one after the other.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import pbio.misc.logging_utils as logging_utils\n",
    "import pbio.misc.mpl_utils as mpl_utils\n",
    "import pbio.ribo.ribo_utils as ribo_utils\n",
    "\n",
    "args = Namespace()\n",
    "logger = logging_utils.get_ipython_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# graphics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set({\"ytick.direction\": u'out'}, style='white') #color_codes=True, palette='muted')\n",
    "\n",
    "params = {\n",
    "   'axes.labelsize': 28,\n",
    "   'font.size': 28,\n",
    "   'legend.fontsize': 26,\n",
    "   'xtick.labelsize': 26,\n",
    "   'ytick.labelsize': 26,\n",
    "   \"lines.linewidth\": 2.5,\n",
    "   'text.usetex': True,\n",
    "   'figure.figsize': [12, 8],\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': 'DejaVu Sans',\n",
    "    'mathtext.fontset': 'dejavusans'\n",
    "   }\n",
    "plt.rcParams.update(params)\n",
    "font = FontProperties().copy()\n",
    "\n",
    "args.fontsize = params['legend.fontsize']\n",
    "args.legend_fontsize = params['legend.fontsize']\n",
    "args.labelsize =params['axes.labelsize']\n",
    "\n",
    "import logging\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I/O - \"configuration file\" and parameters/options\n",
    "\n",
    "# If you run the downsampled data, you will need to adjust the path to the configuration file and the results file\n",
    "# args.baseloc abd args.dirloc, as well as the name of the files configs and alignment_counts_files.\n",
    "\n",
    "args.baseloc = '/beegfs/pub/hbigs_course_2019/ribosome-profiling/riboSeqHBIGS19-analysis/config'\n",
    "args.dirloc = '/beegfs/pub/hbigs_course_2019/ribosome-profiling/riboSeqHBIGS19-analysis/analysis'\n",
    "\n",
    "# config file for the project to read in the sample name map\n",
    "configs = {\n",
    "    'hbigs': os.path.join(args.baseloc, \"hbigs19.yaml\")\n",
    "}\n",
    "\n",
    "alignment_counts_files = {\n",
    "    'hbigs': os.path.join(args.dirloc, \"HBIGS19.read-filtering-counts.csv.gz\")\n",
    "}\n",
    "\n",
    "read_lengths = {\n",
    "    'hbigs': os.path.join(args.dirloc, \"HBIGS19.read-length-distributions-unique.csv.gz\")\n",
    "}\n",
    "\n",
    "periodic_lengths = {\n",
    "    'hbigs': os.path.join(args.dirloc, \"HBIGS19.periodic-length-and-offsets.csv.gz\")\n",
    "}\n",
    "\n",
    "counts = {\n",
    "    'hbigs': os.path.join(args.dirloc, \"HBIGS19.counts-per-frame.csv.gz\")\n",
    "}\n",
    "\n",
    "\n",
    "data = 'hbigs'\n",
    "title_str = 'Ribo-seq'\n",
    "\n",
    "args.without_rrna = False\n",
    "# args.without_rrna = True\n",
    "\n",
    "# customise scale\n",
    "ymax = 8.0e7\n",
    "ystep = 1.0e7\n",
    "ymax_without_rrna = 5.0e7\n",
    "ystep_without_rrna = 1.0e7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# READ FILTERING COUNT\n",
    "\n",
    "if args.without_rrna:\n",
    "    args.ymax = ymax_without_rrna\n",
    "    args.ystep = ystep_without_rrna\n",
    "else:\n",
    "    args.ymax = ymax\n",
    "    args.ystep = ystep\n",
    "\n",
    "\n",
    "args.alignment_counts_order = [\n",
    "    'raw_data_count', \n",
    "    'without_adapters_count', \n",
    "    'without_rrna_count', \n",
    "    'genome_count', \n",
    "    'unique_count', \n",
    "    'length_count'\n",
    "]\n",
    "\n",
    "args.alignment_counts_names = [\n",
    "    'Poor quality', \n",
    "    'Ribosomal', \n",
    "    'No alignment', \n",
    "    'Multimappers', \n",
    "    'Non-periodic', \n",
    "    'Usable'\n",
    "]\n",
    "\n",
    "args.without_rrna_order = [\n",
    "    'without_rrna_count', \n",
    "    'genome_count', \n",
    "    'unique_count', \n",
    "    'length_count'\n",
    "]\n",
    "\n",
    "args.without_rrna_names = [\n",
    "    \"No alignment\", \n",
    "    \"Multimappers\", \n",
    "    \"Non-periodic\", \n",
    "    \"Usable\"\n",
    "]\n",
    "\n",
    "if args.without_rrna:\n",
    "    args.alignment_counts_order = args.without_rrna_order\n",
    "    args.alignment_counts_names = args.without_rrna_names\n",
    "\n",
    "args.alignment_counts = alignment_counts_files[data]\n",
    "\n",
    "args.alignment_counts_order = args.alignment_counts_order[::-1]\n",
    "args.alignment_counts_names = args.alignment_counts_names[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msg = \"Reading counts\"\n",
    "logger.info(msg)\n",
    "\n",
    "alignment_counts = pd.read_csv(args.alignment_counts)\n",
    "\n",
    "config = yaml.load(open(configs[data]), Loader=yaml.FullLoader)\n",
    "sample_name_map = ribo_utils.get_sample_name_map(config)\n",
    "\n",
    "alignment_counts = alignment_counts.sort_values('note').reset_index()\n",
    "\n",
    "names = alignment_counts['note']\n",
    "\n",
    "alignment_diff_counts = mpl_utils.get_diff_counts(alignment_counts[args.alignment_counts_order])\n",
    "df = pd.DataFrame(alignment_diff_counts)\n",
    "df.columns = args.alignment_counts_names\n",
    "df['name'] = names.reset_index(drop=True)\n",
    "\n",
    "df['display_name'] = df['name'].apply(lambda x: sample_name_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "pal = sns.palettes.color_palette(palette=\"Set3\", n_colors=len(args.alignment_counts_names))\n",
    "\n",
    "gap = .2\n",
    "yticks = np.arange(0, args.ymax, args.ystep)\n",
    "\n",
    "bars = mpl_utils.create_stacked_bar_graph(\n",
    "    ax,\n",
    "    alignment_diff_counts,\n",
    "    colors=pal,\n",
    "    x_tick_labels=df['display_name'],\n",
    "    y_ticks=yticks,\n",
    "    y_tick_labels=yticks,\n",
    "    gap=gap,\n",
    "    end_gaps=True,\n",
    "    stack_labels=args.alignment_counts_names,\n",
    "    y_title='Ribo-seq reads',\n",
    "    log=False,\n",
    "    font_size=args.fontsize,\n",
    "    label_font_size=args.labelsize,\n",
    "    edge_colors='1'\n",
    ")\n",
    "\n",
    "leg = ax.legend(bbox_to_anchor=(1, 0), \n",
    "                loc=\"lower left\",\n",
    "                bbox_transform=ax.transAxes, \n",
    "                columnspacing=0.5,\n",
    "                fontsize=args.legend_fontsize,\n",
    "                frameon=False,\n",
    "                ncol=1)\n",
    "\n",
    "if args.without_rrna:\n",
    "    ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0e'))\n",
    "else:\n",
    "    ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0e'))\n",
    "    \n",
    "mpl_utils.set_label_fontsize(ax, args.fontsize)\n",
    "mpl_utils.set_legend_title_fontsize(ax, args.fontsize)\n",
    "\n",
    "ax.set_title(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # FOOTPRINT LENGTH DISTRIBUTION\n",
    "\n",
    "args.reads = read_lengths[data]\n",
    "args.periodic = periodic_lengths[data]\n",
    "args.out = read_lengths[data]\n",
    "\n",
    "msg = \"Reading counts\"\n",
    "logger.info(msg)\n",
    "\n",
    "reads = pd.read_csv(args.reads, sep=',')\n",
    "periodic = pd.read_csv(args.periodic, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset_samples = ['EGF', 'PBS'] # the two conditions\n",
    "all_lengths_list = []\n",
    "for sample in subset_samples:\n",
    "    m_subset = periodic['condition'].str.contains('^'+sample)\n",
    "    periodic_sub = periodic[m_subset]\n",
    "\n",
    "    all_lengths = defaultdict(list) \n",
    "    all_names = periodic_sub['condition'].unique()\n",
    "    for name in all_names:\n",
    "        lengths = [str(l) for l in periodic_sub[periodic_sub['condition']==name].lengths.values]\n",
    "        for l in lengths:\n",
    "            all_lengths[l].append(reads[reads['condition']==name][lengths[lengths.index(l)]].values[0])\n",
    "\n",
    "    all_lengths_df = pd.DataFrame.from_dict(all_lengths, orient='index').T.unstack().reset_index() \n",
    "    all_lengths_df['Model'] = sample\n",
    "    all_lengths_list.append(all_lengths_df)\n",
    "    \n",
    "all_lengths_df = pd.concat(all_lengths_list)\n",
    "all_lengths_df = all_lengths_df[~all_lengths_df[0].isna()].copy()\n",
    "all_lengths_df.rename(columns={'level_0':'Periodic footprint length (nt)', 0:'Ribo-seq reads'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "pal = sns.palettes.color_palette(palette=\"Set3\", n_colors=6)\n",
    "pal = [pal[4], pal[3]]\n",
    "\n",
    "flatui = [\"#3498db\", \"#e74c3c\"] # \"#95a5a6\" \"##9b59b6\"\n",
    "hue_palette = sns.color_palette(flatui)\n",
    "\n",
    "# sns.catplot(x=\"level_0\", y=0, kind=\"swarm\", data=df)\n",
    "g = sns.swarmplot(x=\"Periodic footprint length (nt)\", y='Ribo-seq reads', data=all_lengths_df, color=pal[0], size=8, ax=ax,\n",
    "                 edgecolor=pal[0], hue='Model', hue_order=subset_samples, \n",
    "                  palette=hue_palette)\n",
    "\n",
    "leg = ax.legend(loc=\"upper right\",\n",
    "                columnspacing=0.5,\n",
    "                fontsize=params['legend.fontsize'],\n",
    "                frameon=False,\n",
    "                ncol=1)\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # COUNTS PER FRAME\n",
    "\n",
    "args.counts = counts[data]\n",
    "\n",
    "msg = \"Reading counts\"\n",
    "logger.info(msg)\n",
    "\n",
    "frame_counts = pd.read_csv(args.counts)\n",
    "    \n",
    "frame_counts = frame_counts.sort_values('condition').reset_index()\n",
    "\n",
    "# From raw value to percentage\n",
    "\n",
    "totals = [i+j+k for i,j,k in zip(frame_counts['frame_count'], frame_counts['frame+1_count'], frame_counts['frame+2_count'])]\n",
    "frame1 = [i / j * 100 for i,j in zip(frame_counts['frame_count'], totals)]\n",
    "frame2 = [i / j * 100 for i,j in zip(frame_counts['frame+1_count'], totals)]\n",
    "frame3 = [i / j * 100 for i,j in zip(frame_counts['frame+2_count'], totals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "pal = sns.palettes.color_palette(palette=\"Set3\", n_colors=6)\n",
    "\n",
    "names = frame_counts['condition']\n",
    "r = range(len(names))\n",
    "\n",
    "barWidth = .95\n",
    "ax.bar(r, frame1, color=pal[0], edgecolor='white', width=barWidth, label='Reading frame')\n",
    "ax.bar(r, frame2, bottom=frame1, color=pal[1], edgecolor='white', width=barWidth, label='Reading frame +1')\n",
    "ax.bar(r, frame3, bottom=[i+j for i,j in zip(frame1,frame2)], color=pal[2], edgecolor='white', width=barWidth, label='Reading frame +2')\n",
    "plt.xticks(r, names, rotation='vertical')\n",
    "# ax.set_ylabel('Periodic,\\nP-site shifted reads (\\%)')\n",
    "ax.set_ylabel('P-sites (\\%)')\n",
    "ax.legend(loc='upper right',\n",
    "             bbox_to_anchor=(1.45, 1.),\n",
    "    ncol=1,\n",
    "    frameon=False,\n",
    "    framealpha=0.9\n",
    ")\n",
    "ax.set_title(title_str)\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing analysis\n",
    "***\n",
    "\n",
    "In addition to the above, the `create-rpbp-preprocessing-report` script can be used to generate a latex document and several plots that summarize the preprocessing and ORF profile construction (among which you will recognise the first figure above, generated using the first 6 cells). During the report creation step, a file *read-filtering-counts.csv.gz* will be generated, which you can use to create the *read filtering count figures* above.\n",
    "\n",
    "We have ran this script on the data, and we will examine the report, located under */beegfs/pub/hbigs_course_2019/ribosome-profiling/riboSeqHBIGS19-analysis/riboseq-results/HBIGS19preprocessing-report/preprocessing-report.pdf*.\n",
    "\n",
    "\n",
    "&#9655;  **Self-guided learning**  You can try running the preprocessing analysis yourself on the downsampled data, using the previous notebook (making sure you are in the course directory under *riboSeqHBIGS19-downsampled-analysis/config*). To do that, copy the cell starting with the `%%sbatch` line, remove all lines from 9, starting with `run-all-rpbp-instances`, and replace them with the following lines. You need to adjust the second line and replace *course01* with your username.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create-rpbp-preprocessing-report hbigs19-downsampled.yaml \\\n",
    "    /home/course01/hbigs_course_2019/ribosome-profiling/riboSeqHBIGS19-downsampled-analysis/riboseq-results/report \\\n",
    "    --num-cpus 6 \\\n",
    "    --mem 120G \\\n",
    "    --logging-level INFO \\\n",
    "    --log-file report-downsampled.log\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.3 Prediction analysis: understand the output of rpbp\n",
    "\n",
    "In this section, we will briefly explore the structure of the output of `rpbp`, select a number of examples, and visualise the ORF predictions in a descriptive way. \n",
    "\n",
    "&#9655; **Beyond this introduction** The ORF predictions can be used as starting point for an indepth analysis of a dataset/experiment, by performing *e.g.* conservation, sequence/motif analyses, *etc.* or be used in combination with RNA-seq to perform translational efficiency analysis (see Part 2).\n",
    "\n",
    "\n",
    "**Note** There is a command that can be used to generate a report (similar to the preprocesing analysis), called `create-rpbp-predictions-report` (see [Predictions analysis](https://rp-bp.readthedocs.io/en/latest/analysis-scripts.html#predictions-analysis)). We are currently working on a \"next-generation\" solution to the pdf report/figures!\n",
    "\n",
    "***\n",
    "<font color=red>**Note** The cells below contain \"code\", so we will need to run them one after the other.</font> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pbio.utils.bed_utils as bed_utils\n",
    "\n",
    "orfs = {\n",
    "    'hbigs': os.path.join(args.dirloc, \"HBIGS19.filtered.predicted-orfs.bed.gz\")\n",
    "}\n",
    "args.orfs = orfs[data]\n",
    "predicted_orfs = bed_utils.read_bed(args.orfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The results are displayed as an extended BED file.\n",
    "# See https://www.ensembl.org/info/website/upload/bed.html (BED File Format)\n",
    "\n",
    "# We run this cell, with the name of the results table, called a dataframe, to see the output.\n",
    "# We will explain the different fields...\n",
    "\n",
    "predicted_orfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, they show how EGF stimulation results in distinct \"waves\" of protein synthesis. Proteins whose synthesis was statistically significantly altered in at least one time point were subjected to hierarchical clustering.\n",
    "\n",
    "We pick 2 genes from cluster 1 (characterized by increased protein synthesis as early as 30 min following EGF stimulation): EGR1 (refered to as a canonical immediate early gene or IEG, *i.e* a gene that is rapidly up-regulated within the first hour following stimulus) and ATF3 (a \"classical\" delayed early gene; in contrast to established literature, this one appears to be rapidly down-regulated after 15 min following EGF stimulation, then up-regulated after 30 min)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mEGR1 = predicted_orfs['id'].str.contains('ENST00000239938') # one EGR1 transcript\n",
    "predicted_orfs[mEGR1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mATF3 = predicted_orfs['id'].str.contains('ENST00000492118') # one ATF3 transcript\n",
    "predicted_orfs[mATF3]\n",
    "\n",
    "# What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice from the output above?\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<div>\n",
    "<img src=\"img/Human_ATF3.png\" width=\"900\" align=\"center\"/>\n",
    "</div>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "ATF3 is a gene encoding an activation transcription factor. This gene is induced by a variety of signals, including cellular stress response. \n",
    "\n",
    "Another member of this family is ATF4. The translation of ATF4 is known to be dependent on uORFs. In particular, during normal conditions, uORFs repress translation of the main ATF4 CDS, while under stress conditions ATF4 is translated.\n",
    "\n",
    "What do you notice from the output below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mATF4 = predicted_orfs['id'].str.contains('ENST00000404241') # one ATF4 transcript\n",
    "predicted_orfs[mATF4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use all predictions from the `rpbp` pipeline, and look at the distribution of ORFs (*i.e.* translatable ORFs which were predicted with a certain confidence to actually be translated, using the Ribo-seq data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the ORF counts per strand\n",
    "\n",
    "orf_type_counts = predicted_orfs.groupby(['orf_type', 'strand']).size()\n",
    "orf_type_counts = orf_type_counts.reset_index(name=\"count\")\n",
    "orf_type_counts['display_name'] = orf_type_counts['orf_type'].map(ribo_utils.orf_type_display_name_map)\n",
    "\n",
    "# orf_type_counts = orf_type_counts[orf_type_counts['orf_type']!='canonical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orf_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color = sns.palettes.color_palette(\"Set3\", n_colors=3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "sns.barplot(\n",
    "    x=\"display_name\",\n",
    "    y=\"count\",\n",
    "    hue=\"strand\",\n",
    "    data=orf_type_counts,\n",
    "    ax=ax,\n",
    "    zorder=-1,\n",
    "    palette='Set3',\n",
    "    log=True\n",
    ")\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "ax.legend(\n",
    "    loc='upper right', \n",
    "    bbox_to_anchor=(1.3, 1.3), \n",
    "    fontsize=params['legend.fontsize'],\n",
    "    frameon=False,\n",
    "    title=\"Strand\"\n",
    ")\n",
    "mpl_utils.set_legend_title_fontsize(ax, args.fontsize)\n",
    "\n",
    "ax.set_ylabel(\"Number of ORFs\", fontsize=args.fontsize)\n",
    "ax.set_xlabel(\"\", fontsize=0)\n",
    "\n",
    "# rotate the ORF type names\n",
    "mpl_utils.set_ticklabels_fontsize(ax, args.fontsize)\n",
    "mpl_utils.set_ticklabel_rotation(ax, axis='x', rotation=90)\n",
    "\n",
    "# place the ORF type names in the middle of the bar\n",
    "for ticklabel in ax.xaxis.get_ticklabels():    \n",
    "    p = ticklabel.get_position()\n",
    "    ticklabel.set_position((p[0], 0.1))\n",
    "    ticklabel.set_verticalalignment('bottom')\n",
    "\n",
    "ax.set_title(title_str, fontsize=args.fontsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "MIT License (code and scripts)\n",
    "\n",
    "Copyright (c) 2019 Etienne Boileau"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
